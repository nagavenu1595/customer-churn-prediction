{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# For reproducibility\n",
    "import numpy as np\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5634, 10)\n",
      "X_test shape: (1409, 10)\n",
      "y_train distribution:\n",
      "Churn\n",
      "0    4139\n",
      "1    1495\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Preprocessed & Feature-Selected Data\n",
    "# Make sure you have run your merged data_preprocessing.py before this notebook\n",
    "X_train = pd.read_csv(\"../data/processed/X_train_selected.csv\")\n",
    "X_test  = pd.read_csv(\"../data/processed/X_test_selected.csv\")\n",
    "y_train = pd.read_csv(\"../data/processed/y_train.csv\").squeeze()\n",
    "y_test  = pd.read_csv(\"../data/processed/y_test.csv\").squeeze()\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train distribution:\")\n",
    "print(y_train.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters (XGBoost): {'model__learning_rate': 0.2, 'model__max_depth': 5, 'model__n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nagar\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:35:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/best_model_xgb.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3: Hyperparameter Tuning with XGBoost\n",
    "# Create a pipeline using XGBClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('model', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'model__n_estimators': [50, 100, 200],\n",
    "    'model__max_depth': [3, 5, 7],\n",
    "    'model__learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Set up grid search (using F1 score for evaluation)\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best hyperparameters (XGBoost):\", grid.best_params_)\n",
    "\n",
    "# Save the best estimator (optional)\n",
    "joblib.dump(grid.best_estimator_, '../models/best_model_xgb.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (XGBoost):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.70      0.79      1035\n",
      "           1       0.49      0.80      0.61       374\n",
      "\n",
      "    accuracy                           0.73      1409\n",
      "   macro avg       0.70      0.75      0.70      1409\n",
      "weighted avg       0.80      0.73      0.74      1409\n",
      "\n",
      "ROC AUC: 0.7523\n",
      "Final XGBoost model saved as 'models/final_model_xgb.pkl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nagar\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:36:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Handle Class Imbalance with SMOTE and Train Final Model\n",
    "# Apply SMOTE to training data to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Load best estimator from hyperparameter tuning (or use grid.best_estimator_)\n",
    "model = joblib.load('../models/best_model_xgb.pkl')\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report (XGBoost):\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "# Save the final model\n",
    "joblib.dump(model, '../models/final_model_xgb.pkl')\n",
    "print(\"Final XGBoost model saved as 'models/final_model_xgb.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types:\n",
      " customerID           object\n",
      "gender               object\n",
      "SeniorCitizen         int64\n",
      "Partner              object\n",
      "Dependents           object\n",
      "tenure                int64\n",
      "PhoneService         object\n",
      "MultipleLines        object\n",
      "InternetService      object\n",
      "OnlineSecurity       object\n",
      "OnlineBackup         object\n",
      "DeviceProtection     object\n",
      "TechSupport          object\n",
      "StreamingTV          object\n",
      "StreamingMovies      object\n",
      "Contract             object\n",
      "PaperlessBilling     object\n",
      "PaymentMethod        object\n",
      "MonthlyCharges      float64\n",
      "TotalCharges         object\n",
      "Churn                object\n",
      "dtype: object\n",
      "Model Accuracy: 0.80\n",
      "‚úÖ Model & Scaler saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# üöÄ Load dataset\n",
    "df = pd.read_csv(\"../data/raw/churn.csv\")  # Make sure this file exists in your directory\n",
    "\n",
    "# üîç Check data types (to confirm categorical variables)\n",
    "print(\"Data Types:\\n\", df.dtypes)\n",
    "\n",
    "# ‚úÖ Convert categorical variables using One-Hot Encoding\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# üéØ Define Features & Target\n",
    "TARGET = \"Churn_Yes\"  # After one-hot encoding, \"Churn\" becomes \"Churn_Yes\"\n",
    "FEATURES = [col for col in df.columns if col != TARGET]  # Select all columns except target\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[TARGET]\n",
    "\n",
    "# üîÄ Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# üìè Scale the numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# üå≤ Train a RandomForest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# üìà Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# üíæ Save the model & scaler\n",
    "with open(\"model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "with open(\"scaler.pkl\", \"wb\") as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n",
    "\n",
    "print(\"‚úÖ Model & Scaler saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
